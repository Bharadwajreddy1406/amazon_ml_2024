{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T03:09:29.654056Z",
     "start_time": "2024-09-16T03:09:29.644456Z"
    }
   },
   "source": [
    "import re\n",
    "import easyocr\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import random\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image, ImageEnhance\n",
    "from io import BytesIO\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T03:09:31.008015Z",
     "start_time": "2024-09-16T03:09:30.988066Z"
    }
   },
   "source": [
    "\n",
    "def display_comparison(original_image, preprocessed_image):\n",
    "\tfig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "\t# Original Image\n",
    "\taxes[0].imshow(original_image)\n",
    "\taxes[0].set_title('Original Image')\n",
    "\taxes[0].axis('off')\n",
    "\n",
    "\t# Preprocessed Image\n",
    "\taxes[1].imshow(preprocessed_image, cmap='gray')\n",
    "\taxes[1].set_title('Preprocessed Image')\n",
    "\taxes[1].axis('off')\n",
    "\n",
    "\tplt.tight_layout()\n",
    "\tplt.show()\n",
    "\n",
    "\n",
    "def preprocess_image(image, target_size=(1200, 900), contrast_factor=1.5):\n",
    "\topen_cv_image = np.array(image)\n",
    "\n",
    "\t# Resize the image\n",
    "\tresized_image = cv2.resize(open_cv_image, target_size, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "\tenhancer = ImageEnhance.Contrast(image)\n",
    "\tenhanced_image = enhancer.enhance(contrast_factor)\n",
    "\topen_cv_image = np.array(enhanced_image)\n",
    "\n",
    "\tgray_image = cv2.cvtColor(open_cv_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\tclahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "\tclahe_image = clahe.apply(gray_image)\n",
    "\n",
    "\tbinary_image = cv2.adaptiveThreshold(clahe_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "\tblurred_image = cv2.medianBlur(binary_image, 5)\n",
    "\n",
    "\t# Edge detection\n",
    "\tedges = cv2.Canny(blurred_image, 100, 200)\n",
    "\n",
    "\t# Convert the preprocessed image back to PIL\n",
    "\tpreprocessed_pil_image = Image.fromarray(edges)\n",
    "\n",
    "\treturn preprocessed_pil_image, enhanced_image\n"
   ],
   "outputs": [],
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T03:09:34.334573Z",
     "start_time": "2024-09-16T03:09:34.310983Z"
    }
   },
   "source": [
    "\n",
    "def extract_text_from_image(image_path, use_cuda=True):\n",
    "\treader = easyocr.Reader(['en'], gpu=use_cuda)\n",
    "\tresult = reader.readtext(image_path)\n",
    "\treturn result\n",
    "\n",
    "\n",
    "def clean_extracted_text(extracted_text):\n",
    "\tcleaned_data = []\n",
    "\t# Patterns\n",
    "\n",
    "\tsingle_number_unit_pattern = r'.*?(\\d+(\\.\\d+)?|\\d+,\\d+)\\s*(CM|FT|IN|MM|MG|KG|UG|MG|G|OZ|LB|TON|KV|MV|V|W|KW|CL|CU_FT|CU_IN|CUP|DL|FL_OZ|GAL|IMP_GAL|L|UL|ML|PT|QT|YD|H|cm|ft|in|mm|mg|kg|ug|g|oz|lb|ton|kv|mv|v|w|kw|cl|cu_ft|cu_in|cup|dl|fl_oz|gal|imp_gal|l|ul|ml|pt|qt|yd|h).*?'\n",
    "\trange_pattern = r'(\\d+(\\.\\d+)?|\\d+,\\d+)\\s*(CM|FT|IN|MM|MG|KG|UG|MG|G|OZ|LB|TON|KV|MV|V|W|KW|CL|CU_FT|CU_IN|CUP|DL|FL_OZ|GAL|IMP_GAL|L|UL|ML|PT|QT|YD|H|cm|ft|in|mm|mg|kg|ug|g|oz|lb|ton|kv|mv|v|w|kw|cl|cu_ft|cu_in|cup|dl|fl_oz|gal|imp_gal|l|ul|ml|pt|qt|yd|h)\\s*to\\s*(\\d+(\\.\\d+)?|\\d+,\\d+)\\s*(CM|FT|IN|MM|MG|KG|UG|MG|G|OZ|LB|TON|KV|MV|V|W|KW|CL|CU_FT|CU_IN|CUP|DL|FL_OZ|GAL|IMP_GAL|L|UL|ML|PT|QT|YD|H|cm|ft|in|mm|mg|kg|ug|g|oz|lb|ton|kv|mv|v|w|kw|cl|cu_ft|cu_in|cup|dl|fl_oz|gal|imp_gal|l|ul|ml|pt|qt|yd|h)'\n",
    "\tmultiple_numbers_pattern = r'((\\d+(\\.\\d+)?|\\d+,\\d+)(,\\s*\\d+(\\.\\d+)?|\\d+,\\d+)*?)\\s*(CM|FT|IN|MM|MG|KG|UG|MG|G|OZ|LB|TON|KV|MV|V|W|KW|CL|CU_FT|CU_IN|CUP|DL|FL_OZ|GAL|IMP_GAL|L|UL|ML|PT|QT|YD|H|cm|ft|in|mm|mg|kg|ug|g|oz|lb|ton|kv|mv|v|w|kw|cl|cu_ft|cu_in|cup|dl|fl_oz|gal|imp_gal|l|ul|ml|pt|qt|yd|h)'\n",
    "\tbracketed_range_pattern = r'\\[\\s*(\\d+(\\.\\d+)?|\\d+,\\d+)\\s*,\\s*(\\d+(\\.\\d+)?|\\d+,\\d+)\\s*\\]\\s*(CM|FT|IN|MM|MG|KG|UG|MG|G|OZ|LB|TON|KV|MV|V|W|KW|CL|CU_FT|CU_IN|CUP|DL|FL_OZ|GAL|IMP_GAL|L|UL|ML|PT|QT|YD|H|cm|ft|in|mm|mg|kg|ug|g|oz|lb|ton|kv|mv|v|w|kw|cl|cu_ft|cu_in|cup|dl|fl_oz|gal|imp_gal|l|ul|ml|pt|qt|yd|h)'\n",
    "\n",
    "\tfor text in extracted_text:\n",
    "\t\tmatch = re.match(range_pattern, text[1])\n",
    "\t\tif match:\n",
    "\t\t\tcleaned_data.append((float(match.group(1).replace(',', '.')), match.group(3)))\n",
    "\t\t\tcleaned_data.append((float(match.group(4).replace(',', '.')), match.group(6)))\n",
    "\t\telse:\n",
    "\t\t\tmatch = re.match(single_number_unit_pattern, text[1])\n",
    "\t\t\tif match:\n",
    "\t\t\t\tcleaned_data.append((float(match.group(1).replace(',', '.')), match.group(3)))\n",
    "\t\t\telse:\n",
    "\t\t\t\tmatch = re.match(multiple_numbers_pattern, text[1])\n",
    "\t\t\t\tif match:\n",
    "\t\t\t\t\tnumbers = match.group(1).split(',')\n",
    "\t\t\t\t\tfor number in numbers:\n",
    "\t\t\t\t\t\tcleaned_data.append((float(number.strip().replace(',', '.')), match.group(6)))\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tmatch = re.match(bracketed_range_pattern, text[1])\n",
    "\t\t\t\t\tif match:\n",
    "\t\t\t\t\t\tcleaned_data.append((float(match.group(1).replace(',', '.')), match.group(5)))\n",
    "\t\t\t\t\t\tcleaned_data.append((float(match.group(3).replace(',', '.')), match.group(5)))\n",
    "\treturn cleaned_data\n",
    "\n",
    "\n",
    "def map_units(cleaned_data):\n",
    "\tunit_conversion_map = {\n",
    "\t\t'cm': 'centimetre',\n",
    "\t\t'CM': 'centimetre',\n",
    "\t\t'ft': 'foot',\n",
    "\t\t'FT': 'foot',\n",
    "\t\t'in': 'inch',\n",
    "\t\t'IN': 'inch',\n",
    "\t\t'm': 'metre',\n",
    "\t\t'M': 'metre',\n",
    "\t\t'mm': 'millimetre',\n",
    "\t\t'MM': 'millimetre',\n",
    "\t\t'yd': 'yard',\n",
    "\t\t'YD': 'yard',\n",
    "\t\t'g': 'gram',\n",
    "\t\t'G': 'gram',\n",
    "\t\t'kg': 'kilogram',\n",
    "\t\t'KG': 'kilogram',\n",
    "\t\t'ug': 'microgram',\n",
    "\t\t'UG': 'microgram',\n",
    "\t\t'mg': 'milligram',\n",
    "\t\t'MG': 'milligram',\n",
    "\t\t'oz': 'ounce',\n",
    "\t\t'OZ': 'ounce',\n",
    "\t\t'lb': 'pound',\n",
    "\t\t'LB': 'pound',\n",
    "\t\t'ton': 'ton',\n",
    "\t\t'TON': 'ton',\n",
    "\t\t'kv': 'kilovolt',\n",
    "\t\t'KV': 'kilovolt',\n",
    "\t\t'mv': 'millivolt',\n",
    "\t\t'MV': 'millivolt',\n",
    "\t\t'v': 'volt',\n",
    "\t\t'V': 'volt',\n",
    "\t\t'w': 'watt',\n",
    "\t\t'W': 'watt',\n",
    "\t\t'kw': 'kilowatt',\n",
    "\t\t'KW': 'kilowatt',\n",
    "\t\t'cl': 'centilitre',\n",
    "\t\t'CL': 'centilitre',\n",
    "\t\t'cu_ft': 'cubic foot',\n",
    "\t\t'CU_FT': 'cubic foot',\n",
    "\t\t'cu_in': 'cubic inch',\n",
    "\t\t'CU_IN': 'cubic inch',\n",
    "\t\t'cup': 'cup',\n",
    "\t\t'CUP': 'cup',\n",
    "\t\t'dl': 'decilitre',\n",
    "\t\t'DL': 'decilitre',\n",
    "\t\t'fl_oz': 'fluid ounce',\n",
    "\t\t'FL_OZ': 'fluid ounce',\n",
    "\t\t'gal': 'gallon',\n",
    "\t\t'GAL': 'gallon',\n",
    "\t\t'imp_gal': 'imperial gallon',\n",
    "\t\t'IMP_GAL': 'imperial gallon',\n",
    "\t\t'l': 'litre',\n",
    "\t\t'L': 'litre',\n",
    "\t\t'ul': 'microlitre',\n",
    "\t\t'UL': 'microlitre',\n",
    "\t\t'ml': 'millilitre',\n",
    "\t\t'ML': 'millilitre',\n",
    "\t\t'pt': 'pint',\n",
    "\t\t'PT': 'pint',\n",
    "\t\t'qt': 'quart',\n",
    "\t\t'QT': 'quart',\n",
    "\t\t'h': 'hour',\n",
    "\t\t'H': 'hour'\n",
    "\t}\n",
    "\tallowed_units = set(unit_conversion_map.values())\n",
    "\tmapped_data = []\n",
    "\tfor number, unit in cleaned_data:\n",
    "\t\tif unit in unit_conversion_map:\n",
    "\t\t\tmapped_unit = unit_conversion_map[unit]\n",
    "\t\t\tif mapped_unit in allowed_units:\n",
    "\t\t\t\tmapped_data.append((number, mapped_unit))\n",
    "\treturn mapped_data\n",
    "\n",
    "\n",
    "def process_images(df):\n",
    "\textracted_data = []\n",
    "\tcleaned_data = []\n",
    "\n",
    "\ti = 0\n",
    "\t# Iterate over each row in the DataFrame\n",
    "\tfor index, row in df.iterrows():\n",
    "\t\ttry:\n",
    "\t\t\timage_path = row['image_path']\n",
    "\t\t\t# print(image_path, row[\"image_name\"])\n",
    "\t\t\tif row[\"image_name\"] in image_path:\n",
    "\t\t\t\t# print(\"Image path found\", row[\"image_name\"], row[\"image_path\"])\n",
    "\n",
    "\t\t\t\tif pd.notna(image_path):  # Check if image path exists\n",
    "\n",
    "\t\t\t\t\t# print(\"HERE !!!!!!!!!!\")\n",
    "\n",
    "\t\t\t\t\t# Step 1: Preprocess the image\n",
    "\t\t\t\t\toriginal_image = Image.open(image_path)\n",
    "\t\t\t\t\tpreprocessed_image, enhanced_image = preprocess_image(original_image)\n",
    "\n",
    "\t\t\t\t\t# Save the enhanced image to a temporary file\n",
    "\t\t\t\t\ttemp_image_path = 'temps/temp_enhanced_image.jpg'\n",
    "\t\t\t\t\tenhanced_image = enhanced_image.convert('RGB')\n",
    "\t\t\t\t\tenhanced_image.save(temp_image_path)\n",
    "\n",
    "\t\t\t\t\t# Step 2: Perform OCR on the image and clean the text\n",
    "\t\t\t\t\textracted_text = extract_text_from_image(temp_image_path, use_cuda=True)\n",
    "\t\t\t\t\tcleaned_text = clean_extracted_text(extracted_text)\n",
    "\t\t\t\t\tmapped_text = map_units(cleaned_text)\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t# print(f\"Mapped = {extracted_text}\")\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t\n",
    "\n",
    "\t\t\t\t\ttorch.cuda.empty_cache()\n",
    "\t\t\t\t\ttorch.cuda.synchronize()\n",
    "\n",
    "\t\t\t\t\t# Append the results to the lists\n",
    "\t\t\t\t\textracted_data.append(mapped_text)\n",
    "\t\t\t\t\tcleaned_data.append(cleaned_text)\n",
    "\n",
    "\t\t\t\t\t# Display the original and enhanced images\n",
    "\t\t\t\t\t# display_comparison(original_image, enhanced_image)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tcleaned_data.append(\"\")\n",
    "\t\t\t\t\textracted_data.append(\"\")\n",
    "\t\texcept Exception as e:\n",
    "\t\t\t# print(e)\n",
    "\t\t\tcleaned_data.append(\"\")\n",
    "\t\t\textracted_data.append(\"\")\n",
    "\t\t\t# print(f\"Error processing image {image_path}: {e}\")\n",
    "\n",
    "\t\n",
    "\t# Step 4: Add the extracted data as a new column in the DataFrame\n",
    "\tdf['extracted_text'] = extracted_data\n",
    "\tdf['cleaned_text'] = cleaned_data\n",
    "\n",
    "\t##########################################################################################\n",
    "\t# df.to_csv('outputs/test_out.csv', index=True)\t\t\t\tExecute safely\n",
    "\t##########################################################################################\n",
    "\treturn df\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T03:09:41.805355Z",
     "start_time": "2024-09-16T03:09:41.797568Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from src.utils import download_images\n",
    "#     # Read the CSV file\n",
    "# train_df = pd.read_csv(r\"dataset/test.csv\")\n",
    "# \n",
    "# \n",
    "# # Extract the image links\n",
    "# image_links = train_df['image_link'].tolist()\n",
    "# # image_links = image_links[]\n",
    "# \n",
    "# \n",
    "# # Specify the download folder\n",
    "# download_folder = 'downs'\n",
    "# \n",
    "# # Call the download_images function\n",
    "# download_images(image_links, download_folder, allow_multiprocessing=False)\n",
    "# \n"
   ],
   "outputs": [],
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T03:10:10.387471Z",
     "start_time": "2024-09-16T03:10:10.109653Z"
    }
   },
   "source": [
    "df = pd.read_csv(r\"dataset/test.csv\")\n",
    "df.rename(columns={\"Unnamed: 0\": \"index\"}, inplace=True)\n",
    "df = df[[\"image_link\"]]\n",
    "\n",
    "\n",
    "df['image_name'] = df['image_link'].apply(lambda x: x.split(\"/\")[-1])\n",
    "\n",
    "\n",
    "download_folder = Path('downloads')\n",
    "image_paths = list(download_folder.glob('*.jpg'))\n",
    "\n",
    "# getting the image names from the folder paths\n",
    "# folder_image_names = {str(image_path).split(\"/\")[-1]: str(image_path) for image_path in image_paths}\n",
    "\n",
    "# Maping them the DataFrame image names to the corresponding image paths\n",
    "# df['image_path'] = df['image_name'].map(folder_image_names)\n",
    "df['image_path'] = \"downloads/\" + df['image_name']\n",
    "\n",
    "# Step 6: Check the result\n",
    "df = df[['image_name', 'image_path']]\n",
    "# process_images(df)\n",
    "df"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            image_name                 image_path\n",
       "0      110EibNyclL.jpg  downloads/110EibNyclL.jpg\n",
       "1      11TU2clswzL.jpg  downloads/11TU2clswzL.jpg\n",
       "2      11gHj8dhhrL.jpg  downloads/11gHj8dhhrL.jpg\n",
       "3      11lshEUmCrL.jpg  downloads/11lshEUmCrL.jpg\n",
       "4      21+i52HRW4L.jpg  downloads/21+i52HRW4L.jpg\n",
       "...                ...                        ...\n",
       "90661  A1q3da5vzbL.jpg  downloads/A1q3da5vzbL.jpg\n",
       "90662  A1q8C45g+0L.jpg  downloads/A1q8C45g+0L.jpg\n",
       "90663  A1rVsIzEtkL.jpg  downloads/A1rVsIzEtkL.jpg\n",
       "90664  A1rdvZ5zDdL.jpg  downloads/A1rdvZ5zDdL.jpg\n",
       "90665  A1tnTUPyr7L.jpg  downloads/A1tnTUPyr7L.jpg\n",
       "\n",
       "[90666 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>110EibNyclL.jpg</td>\n",
       "      <td>downloads/110EibNyclL.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11TU2clswzL.jpg</td>\n",
       "      <td>downloads/11TU2clswzL.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11gHj8dhhrL.jpg</td>\n",
       "      <td>downloads/11gHj8dhhrL.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11lshEUmCrL.jpg</td>\n",
       "      <td>downloads/11lshEUmCrL.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21+i52HRW4L.jpg</td>\n",
       "      <td>downloads/21+i52HRW4L.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90661</th>\n",
       "      <td>A1q3da5vzbL.jpg</td>\n",
       "      <td>downloads/A1q3da5vzbL.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90662</th>\n",
       "      <td>A1q8C45g+0L.jpg</td>\n",
       "      <td>downloads/A1q8C45g+0L.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90663</th>\n",
       "      <td>A1rVsIzEtkL.jpg</td>\n",
       "      <td>downloads/A1rVsIzEtkL.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90664</th>\n",
       "      <td>A1rdvZ5zDdL.jpg</td>\n",
       "      <td>downloads/A1rdvZ5zDdL.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90665</th>\n",
       "      <td>A1tnTUPyr7L.jpg</td>\n",
       "      <td>downloads/A1tnTUPyr7L.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90666 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T03:10:11.556398Z",
     "start_time": "2024-09-16T03:10:11.548328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# import pandas as pd\n",
    "# train_df = pd.read_csv('dataset/test.csv')\n",
    "# \n",
    "# # Check if the dataset has duplicates\n",
    "# if train_df.duplicated(subset=['image_link' ]).any():\n",
    "#     print(\"Duplicates found. Replacing train.csv with unique entries...\")\n",
    "# \n",
    "#     # Remove duplicates\n",
    "#     train_df.drop_duplicates(subset=['image_link'], inplace=True)\n",
    "# \n",
    "#     # Save the updated DataFrame to the original file location (overwrite train.csv)\n",
    "#     train_df.to_csv('dataset/test.csv', index=False)\n",
    "# \n",
    "# print(f\"Final number of rows: {len(train_df)}\")"
   ],
   "outputs": [],
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T03:10:12.632059Z",
     "start_time": "2024-09-16T03:10:12.618445Z"
    }
   },
   "source": "# out = process_images(df)",
   "outputs": [],
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T03:10:12.990950Z",
     "start_time": "2024-09-16T03:10:12.984132Z"
    }
   },
   "source": [
    "# out.sample()"
   ],
   "outputs": [],
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T03:10:13.293568Z",
     "start_time": "2024-09-16T03:10:13.274613Z"
    }
   },
   "source": "# extract_text_from_image(\"temps/temp_enhanced_image.jpg\")",
   "outputs": [],
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T03:10:13.717017Z",
     "start_time": "2024-09-16T03:10:13.708143Z"
    }
   },
   "source": [
    "import torch\n",
    "\n",
    "print(torch.version.cuda)  # Check the version of CUDA being used\n",
    "print(torch.cuda.is_available())  # Should return True\n",
    "print(torch.backends.cudnn.enabled)  # Should return True if CUDNN is working"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.4\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T03:10:15.175794Z",
     "start_time": "2024-09-16T03:10:15.163204Z"
    }
   },
   "source": [
    "def get_ground_truth(filename: 'str', df_to_check: 'pd.DataFrame'):\n",
    "\tactual_path = f\"{filename.split('/')[1]}\"\n",
    "\n",
    "\t# print(actual_path)\n",
    "\n",
    "\treturn df_to_check[df_to_check[\"image_name\"] == actual_path]"
   ],
   "outputs": [],
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T03:10:16.386253Z",
     "start_time": "2024-09-16T03:10:16.371093Z"
    }
   },
   "source": [
    "# train_df = pd.read_csv(\"dataset/train.csv\")\n",
    "# train_df[\"image_name\"] = train_df[\"image_link\"].apply(lambda link: link.split(\"/\")[-1])\n",
    "# train_df = train_df.drop([\"image_link\"], axis=1)\n",
    "# train_df[\"image_path\"] = train_df[\"image_name\"].apply(lambda path: \"test/\" + path)\n",
    "# \n",
    "# out_df = pd.read_csv(\"outputs/test_out.csv\")\n",
    "# out_df = out_df.drop([\"Unnamed: 0\"], axis=1)\n",
    "# \n",
    "# # This means all the images in the out_df are present in the OCR applied images\n",
    "# list(filter(lambda x: x[0] != x[1], list(zip(out_df[\"image_name\"].to_list(), train_df[\"image_name\"].to_list()))))\n",
    "# \n",
    "\n",
    "\n",
    "# get_ground_truth(\"downloads/31EvJszFVfL.jpg\", train_df)\n",
    "# get_ground_truth(\"downloads/31EvJszFVfL.jpg\", train_df)\n",
    "# \n",
    "# get_ground_truth(\"downloads/31EvJszFVfL.jpg\", out_df)"
   ],
   "outputs": [],
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T03:10:16.813190Z",
     "start_time": "2024-09-16T03:10:16.798884Z"
    }
   },
   "source": [
    "# Dropping rows for which the prediction is NaN\n",
    "\n",
    "# out_df = out_df.dropna(axis=0)"
   ],
   "outputs": [],
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T03:10:17.404829Z",
     "start_time": "2024-09-16T03:10:17.387407Z"
    }
   },
   "source": [
    "\n",
    "# out_df.columns"
   ],
   "outputs": [],
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T03:10:17.716126Z",
     "start_time": "2024-09-16T03:10:17.703373Z"
    }
   },
   "source": "# train_df.columns",
   "outputs": [],
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T03:10:18.006360Z",
     "start_time": "2024-09-16T03:10:17.992446Z"
    }
   },
   "source": "# out_df[\"cleaned_text\"].to_list()",
   "outputs": [],
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T03:10:18.221695Z",
     "start_time": "2024-09-16T03:10:18.209493Z"
    }
   },
   "source": "# out_df.info()\n",
   "outputs": [],
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T03:10:18.457546Z",
     "start_time": "2024-09-16T03:10:18.446106Z"
    }
   },
   "source": [
    "# import ast\n",
    "# \n",
    "# # Changing the cols from str to list\n",
    "# \n",
    "# out_df['extracted_text'] = out_df['extracted_text'].apply(ast.literal_eval)\n",
    "# out_df['cleaned_text'] = out_df['cleaned_text'].apply(ast.literal_eval)\n",
    "# "
   ],
   "outputs": [],
   "execution_count": 61
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T03:10:18.593037Z",
     "start_time": "2024-09-16T03:10:18.575475Z"
    }
   },
   "source": "# out_df.info()",
   "outputs": [],
   "execution_count": 62
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T03:10:19.273269Z",
     "start_time": "2024-09-16T03:10:19.256752Z"
    }
   },
   "source": [
    "allowed_units = {\"centilitre\", \"centimetre\", \"cubicfoot\", \"cubicinch\", \"cup\", \"decilitre\", \"fluidounce\", \"foot\", \"gallon\", \"gram\", \"imperialgallon\", \"inch\", \"kilogram\", \"kilovolt\", \"kilowatt\", \"litre\", \"metre\", \"microgram\", \"microlitre\", \"milligram\", \"millilitre\", \"millimetre\", \"millivolt\", \"ounce\", \"pint\", \"pound\", \"quart\", \"ton\", \"volt\", \"watt\", \"yard\"}\n",
    "# Define the allowed units\n",
    "allowed_units = {\n",
    "\t\"centilitre\", \"centimetre\", \"cubicfoot\", \"cubicinch\", \"cup\", \"decilitre\", \n",
    "\t\"fluidounce\", \"foot\", \"gallon\", \"gram\", \"imperialgallon\", \"inch\", \"kilogram\", \n",
    "\t\"kilovolt\", \"kilowatt\", \"litre\", \"metre\", \"microgram\", \"microlitre\", \n",
    "\t\"milligram\", \"millilitre\", \"millimetre\", \"millivolt\", \"ounce\", \"pint\", \n",
    "\t\"pound\", \"quart\", \"ton\", \"volt\", \"watt\", \"yard\"\n",
    "}\n",
    "\n",
    "# Define the abbreviation mapping\n",
    "mapping = {\n",
    "\t\"cl\": \"centilitre\",\n",
    "\t\"cm\": \"centimetre\",\n",
    "\t\"ft\": \"foot\",\n",
    "\t\"in\": \"inch\",\n",
    "\t\"g\": \"gram\",\n",
    "\t\"kg\": \"kilogram\",\n",
    "\t\"l\": \"litre\",\n",
    "\t\"m\": \"metre\",\n",
    "\t\"mg\": \"milligram\",\n",
    "\t\"ml\": \"millilitre\",\n",
    "\t\"oz\": \"ounce\",\n",
    "\t\"pt\": \"pint\",\n",
    "\t\"qt\": \"quart\",\n",
    "\t\"lb\": \"pound\",\n",
    "\t\"gal\": \"gallon\",\n",
    "\t\"cf\": \"cubicfoot\",\n",
    "\t\"ci\": \"cubicinch\",\n",
    "\t\"floz\": \"fluidounce\",\n",
    "\t\"dl\": \"decilitre\",\n",
    "\t\"µg\": \"microgram\",\n",
    "\t\"µl\": \"microlitre\",\n",
    "\t\"mv\": \"millivolt\",\n",
    "\t\"kv\": \"kilovolt\",\n",
    "\t\"kw\": \"kilowatt\",\n",
    "\t\"w\": \"watt\",\n",
    "\t\"yd\": \"yard\",\n",
    "\t\"t\": \"ton\",\n",
    "\t\"imperialgal\": \"imperialgallon\"\n",
    "}\n",
    "\n",
    "mapping\n",
    "\n",
    "\n",
    "def map_shorthand_unit_to_full(pair: 'tuple[str, str]'):\n",
    "\t\n",
    "\tnumber = pair[0]\n",
    "\tunit = pair[1]\n",
    "\n",
    "\tprint(f\"Number={number}, unit={unit}\")\n",
    "\n",
    "\tactual_unit = mapping.get(unit, \"\")\n",
    "\n",
    "\treturn f\"{number} {actual_unit}\"\n",
    "\n",
    "map_shorthand_unit_to_full((\"9.8\", \"g\"))\n",
    "map_shorthand_unit_to_full((\"38\", \"ml\"))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number=9.8, unit=g\n",
      "Number=38, unit=ml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'38 millilitre'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 63
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T03:10:19.814361Z",
     "start_time": "2024-09-16T03:10:19.804082Z"
    }
   },
   "source": [
    "# import tqdm\n",
    "# \n",
    "# \n",
    "# full_match = 0\n",
    "# partial_match = 0\n",
    "# \n",
    "# for idx, row in tqdm.tqdm(out_df.iterrows(), total=out_df.shape[0]):\n",
    "# \n",
    "# \trow = row.to_dict()\n",
    "# \n",
    "# \timage_path = row[\"image_path\"]\n",
    "# \timage_name = row[\"image_name\"]\n",
    "# \tpossible = row[\"extracted_text\"]\n",
    "# \n",
    "# \tpossible = [f\"{pair[0]} {pair[1].lower()}\" for pair in possible]\n",
    "# \n",
    "# \tground_truth = get_ground_truth(image_path, train_df)[\"entity_value\"].tolist()\n",
    "# \n",
    "# \t# print(possible, \"=>\", ground_truth)\n",
    "# \n",
    "# \n",
    "# \t# print(f\"{image_name} => {cleaned_text_list} => {ground_truth}\")\n",
    "# \n",
    "# \tintersection = set(possible).intersection(set(ground_truth))\n",
    "# \n",
    "# \t# print(intersection)\n",
    "# \n",
    "# \tif(len(possible) == 1 and len(intersection) == 1):\n",
    "# \t\tprint(f\"Full match => {possible} => {ground_truth}\")\n",
    "# \t\tfull_match += 1\n",
    "# \n",
    "# \telif(len(intersection) == 1):\n",
    "# \t\tprint(f\"Partial match => {possible} => {ground_truth}\")\n",
    "# \t\tpartial_match += 1\n",
    "# \n",
    "# \t\n",
    "# \n",
    "# print(\"*\" * 100)\n",
    "# print(f\"Full accuracy = {full_match / out_df.shape[0] * 100} %\")\n",
    "# print(f\"Partial accuracy = {partial_match / out_df.shape[0] * 100} %\")\n",
    "# print(\"*\" * 100)\n",
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# \t# if(row != np.nan):\n"
   ],
   "outputs": [],
   "execution_count": 64
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T03:10:20.847446Z",
     "start_time": "2024-09-16T03:10:20.839187Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T03:10:22.799829Z",
     "start_time": "2024-09-16T03:10:22.789904Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now start with testing"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T03:10:29.555725Z",
     "start_time": "2024-09-16T03:10:29.251222Z"
    }
   },
   "source": [
    "import requests\n",
    "\n",
    "# sample_test = pd.read_csv(\"dataset/sample_test.csv\")\n",
    "sample_test = pd.read_csv(\"dataset/test.csv\")\n",
    "\n",
    "sample_test[\"image_path\"] = sample_test[\"image_link\"].apply(lambda link: \"downs/\" + link.split(\"/\")[-1])\n",
    "sample_test[\"image_name\"] = sample_test[\"image_link\"].apply(lambda link: link.split(\"/\")[-1])\n",
    "\n",
    "# sample_test = sample_test.drop([\"image_link\"], axis=1)\n",
    "sample_test"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        index                                         image_link  group_id  \\\n",
       "0           0  https://m.media-amazon.com/images/I/110EibNycl...    156839   \n",
       "1           1  https://m.media-amazon.com/images/I/11TU2clswz...    792578   \n",
       "2           4  https://m.media-amazon.com/images/I/11gHj8dhhr...    792578   \n",
       "3           7  https://m.media-amazon.com/images/I/11lshEUmCr...    156839   \n",
       "4           8  https://m.media-amazon.com/images/I/21+i52HRW4...    478357   \n",
       "...       ...                                                ...       ...   \n",
       "90661  131281  https://m.media-amazon.com/images/I/A1q3da5vzb...    724618   \n",
       "90662  131282  https://m.media-amazon.com/images/I/A1q8C45g+0...    926285   \n",
       "90663  131283  https://m.media-amazon.com/images/I/A1rVsIzEtk...    721522   \n",
       "90664  131284  https://m.media-amazon.com/images/I/A1rdvZ5zDd...    603688   \n",
       "90665  131286  https://m.media-amazon.com/images/I/A1tnTUPyr7...    853009   \n",
       "\n",
       "                         entity_name             image_path       image_name  \n",
       "0                             height  downs/110EibNyclL.jpg  110EibNyclL.jpg  \n",
       "1                              width  downs/11TU2clswzL.jpg  11TU2clswzL.jpg  \n",
       "2                              depth  downs/11gHj8dhhrL.jpg  11gHj8dhhrL.jpg  \n",
       "3                             height  downs/11lshEUmCrL.jpg  11lshEUmCrL.jpg  \n",
       "4                              width  downs/21+i52HRW4L.jpg  21+i52HRW4L.jpg  \n",
       "...                              ...                    ...              ...  \n",
       "90661                    item_weight  downs/A1q3da5vzbL.jpg  A1q3da5vzbL.jpg  \n",
       "90662                    item_weight  downs/A1q8C45g+0L.jpg  A1q8C45g+0L.jpg  \n",
       "90663  maximum_weight_recommendation  downs/A1rVsIzEtkL.jpg  A1rVsIzEtkL.jpg  \n",
       "90664                    item_weight  downs/A1rdvZ5zDdL.jpg  A1rdvZ5zDdL.jpg  \n",
       "90665                    item_weight  downs/A1tnTUPyr7L.jpg  A1tnTUPyr7L.jpg  \n",
       "\n",
       "[90666 rows x 6 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>image_link</th>\n",
       "      <th>group_id</th>\n",
       "      <th>entity_name</th>\n",
       "      <th>image_path</th>\n",
       "      <th>image_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://m.media-amazon.com/images/I/110EibNycl...</td>\n",
       "      <td>156839</td>\n",
       "      <td>height</td>\n",
       "      <td>downs/110EibNyclL.jpg</td>\n",
       "      <td>110EibNyclL.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://m.media-amazon.com/images/I/11TU2clswz...</td>\n",
       "      <td>792578</td>\n",
       "      <td>width</td>\n",
       "      <td>downs/11TU2clswzL.jpg</td>\n",
       "      <td>11TU2clswzL.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>https://m.media-amazon.com/images/I/11gHj8dhhr...</td>\n",
       "      <td>792578</td>\n",
       "      <td>depth</td>\n",
       "      <td>downs/11gHj8dhhrL.jpg</td>\n",
       "      <td>11gHj8dhhrL.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>https://m.media-amazon.com/images/I/11lshEUmCr...</td>\n",
       "      <td>156839</td>\n",
       "      <td>height</td>\n",
       "      <td>downs/11lshEUmCrL.jpg</td>\n",
       "      <td>11lshEUmCrL.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>https://m.media-amazon.com/images/I/21+i52HRW4...</td>\n",
       "      <td>478357</td>\n",
       "      <td>width</td>\n",
       "      <td>downs/21+i52HRW4L.jpg</td>\n",
       "      <td>21+i52HRW4L.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90661</th>\n",
       "      <td>131281</td>\n",
       "      <td>https://m.media-amazon.com/images/I/A1q3da5vzb...</td>\n",
       "      <td>724618</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>downs/A1q3da5vzbL.jpg</td>\n",
       "      <td>A1q3da5vzbL.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90662</th>\n",
       "      <td>131282</td>\n",
       "      <td>https://m.media-amazon.com/images/I/A1q8C45g+0...</td>\n",
       "      <td>926285</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>downs/A1q8C45g+0L.jpg</td>\n",
       "      <td>A1q8C45g+0L.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90663</th>\n",
       "      <td>131283</td>\n",
       "      <td>https://m.media-amazon.com/images/I/A1rVsIzEtk...</td>\n",
       "      <td>721522</td>\n",
       "      <td>maximum_weight_recommendation</td>\n",
       "      <td>downs/A1rVsIzEtkL.jpg</td>\n",
       "      <td>A1rVsIzEtkL.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90664</th>\n",
       "      <td>131284</td>\n",
       "      <td>https://m.media-amazon.com/images/I/A1rdvZ5zDd...</td>\n",
       "      <td>603688</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>downs/A1rdvZ5zDdL.jpg</td>\n",
       "      <td>A1rdvZ5zDdL.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90665</th>\n",
       "      <td>131286</td>\n",
       "      <td>https://m.media-amazon.com/images/I/A1tnTUPyr7...</td>\n",
       "      <td>853009</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>downs/A1tnTUPyr7L.jpg</td>\n",
       "      <td>A1tnTUPyr7L.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90666 rows × 6 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 65
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T03:10:35.911747Z",
     "start_time": "2024-09-16T03:10:35.902336Z"
    }
   },
   "source": [
    "# !rm test/*\n",
    "\n",
    "# for link in sample_test[\"image_link\"].to_list():\n",
    "# \n",
    "# \n",
    "# \n",
    "# \t# continue # Remove to re-execute \n",
    "# \n",
    "# \tfile_name = link.split(\"/\")[-1]\n",
    "# \t# print(file_name)\n",
    "# \n",
    "# \timg = requests.get(link).content\n",
    "# \n",
    "# \twith open(f\"downs/{file_name}\", \"wb\") as f:\n",
    "# \t\tf.write(img)"
   ],
   "outputs": [],
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-09-16T03:10:39.038826Z"
    }
   },
   "source": [
    "# sample_test_out = process_images(sample_test)\n",
    "sample_test = sample_test\n",
    "sample_test_out = process_images(sample_test)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reddy\\PycharmProjects\\amazon_ml\\.venv\\Lib\\site-packages\\easyocr\\detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "C:\\Users\\reddy\\PycharmProjects\\amazon_ml\\.venv\\Lib\\site-packages\\easyocr\\recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T22:55:42.025092Z",
     "start_time": "2024-09-15T22:55:42.007700Z"
    }
   },
   "source": "sample_test_out",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    index                                         image_link  group_id  \\\n",
       "0       0  https://m.media-amazon.com/images/I/110EibNycl...    156839   \n",
       "1       1  https://m.media-amazon.com/images/I/11TU2clswz...    792578   \n",
       "2       4  https://m.media-amazon.com/images/I/11gHj8dhhr...    792578   \n",
       "3       7  https://m.media-amazon.com/images/I/11lshEUmCr...    156839   \n",
       "4       8  https://m.media-amazon.com/images/I/21+i52HRW4...    478357   \n",
       "..    ...                                                ...       ...   \n",
       "95    139  https://m.media-amazon.com/images/I/310oxdFmgL...    913156   \n",
       "96    141  https://m.media-amazon.com/images/I/310p+AOeZ6...    452717   \n",
       "97    142  https://m.media-amazon.com/images/I/310qlaeUSA...    449805   \n",
       "98    144  https://m.media-amazon.com/images/I/310rX4WoAF...    704724   \n",
       "99    147  https://m.media-amazon.com/images/I/310uxz1C1+...    825954   \n",
       "\n",
       "    entity_name             image_path       image_name  \\\n",
       "0        height  downs/110EibNyclL.jpg  110EibNyclL.jpg   \n",
       "1         width  downs/11TU2clswzL.jpg  11TU2clswzL.jpg   \n",
       "2         depth  downs/11gHj8dhhrL.jpg  11gHj8dhhrL.jpg   \n",
       "3        height  downs/11lshEUmCrL.jpg  11lshEUmCrL.jpg   \n",
       "4         width  downs/21+i52HRW4L.jpg  21+i52HRW4L.jpg   \n",
       "..          ...                    ...              ...   \n",
       "95        width  downs/310oxdFmgLL.jpg  310oxdFmgLL.jpg   \n",
       "96       height  downs/310p+AOeZ6L.jpg  310p+AOeZ6L.jpg   \n",
       "97        depth  downs/310qlaeUSAL.jpg  310qlaeUSAL.jpg   \n",
       "98        depth  downs/310rX4WoAFL.jpg  310rX4WoAFL.jpg   \n",
       "99  item_volume  downs/310uxz1C1+L.jpg  310uxz1C1+L.jpg   \n",
       "\n",
       "                                       extracted_text  \\\n",
       "0                                                  []   \n",
       "1           [(42.0, centimetre), (200.0, centimetre)]   \n",
       "2            [(10.5, centimetre), (90.0, centimetre)]   \n",
       "3                                                  []   \n",
       "4                                                       \n",
       "..                                                ...   \n",
       "95          [(100.0, millimetre), (11.5, millimetre)]   \n",
       "96  [(3.0, centimetre), (14.0, centimetre), (3.4, ...   \n",
       "97                                                 []   \n",
       "98                  [(90.0, centimetre), (3.9, inch)]   \n",
       "99                                                 []   \n",
       "\n",
       "                                     cleaned_text  \n",
       "0                                              []  \n",
       "1                       [(42.0, cm), (200.0, cm)]  \n",
       "2                        [(10.5, cm), (90.0, cm)]  \n",
       "3                                              []  \n",
       "4                                                  \n",
       "..                                            ...  \n",
       "95                      [(100.0, mm), (11.5, mm)]  \n",
       "96  [(3.0, cm), (14.0, cm), (3.4, cm), (4.0, cm)]  \n",
       "97                                             []  \n",
       "98                        [(90.0, cm), (3.9, in)]  \n",
       "99                                             []  \n",
       "\n",
       "[100 rows x 8 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>image_link</th>\n",
       "      <th>group_id</th>\n",
       "      <th>entity_name</th>\n",
       "      <th>image_path</th>\n",
       "      <th>image_name</th>\n",
       "      <th>extracted_text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://m.media-amazon.com/images/I/110EibNycl...</td>\n",
       "      <td>156839</td>\n",
       "      <td>height</td>\n",
       "      <td>downs/110EibNyclL.jpg</td>\n",
       "      <td>110EibNyclL.jpg</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://m.media-amazon.com/images/I/11TU2clswz...</td>\n",
       "      <td>792578</td>\n",
       "      <td>width</td>\n",
       "      <td>downs/11TU2clswzL.jpg</td>\n",
       "      <td>11TU2clswzL.jpg</td>\n",
       "      <td>[(42.0, centimetre), (200.0, centimetre)]</td>\n",
       "      <td>[(42.0, cm), (200.0, cm)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>https://m.media-amazon.com/images/I/11gHj8dhhr...</td>\n",
       "      <td>792578</td>\n",
       "      <td>depth</td>\n",
       "      <td>downs/11gHj8dhhrL.jpg</td>\n",
       "      <td>11gHj8dhhrL.jpg</td>\n",
       "      <td>[(10.5, centimetre), (90.0, centimetre)]</td>\n",
       "      <td>[(10.5, cm), (90.0, cm)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>https://m.media-amazon.com/images/I/11lshEUmCr...</td>\n",
       "      <td>156839</td>\n",
       "      <td>height</td>\n",
       "      <td>downs/11lshEUmCrL.jpg</td>\n",
       "      <td>11lshEUmCrL.jpg</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>https://m.media-amazon.com/images/I/21+i52HRW4...</td>\n",
       "      <td>478357</td>\n",
       "      <td>width</td>\n",
       "      <td>downs/21+i52HRW4L.jpg</td>\n",
       "      <td>21+i52HRW4L.jpg</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>139</td>\n",
       "      <td>https://m.media-amazon.com/images/I/310oxdFmgL...</td>\n",
       "      <td>913156</td>\n",
       "      <td>width</td>\n",
       "      <td>downs/310oxdFmgLL.jpg</td>\n",
       "      <td>310oxdFmgLL.jpg</td>\n",
       "      <td>[(100.0, millimetre), (11.5, millimetre)]</td>\n",
       "      <td>[(100.0, mm), (11.5, mm)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>141</td>\n",
       "      <td>https://m.media-amazon.com/images/I/310p+AOeZ6...</td>\n",
       "      <td>452717</td>\n",
       "      <td>height</td>\n",
       "      <td>downs/310p+AOeZ6L.jpg</td>\n",
       "      <td>310p+AOeZ6L.jpg</td>\n",
       "      <td>[(3.0, centimetre), (14.0, centimetre), (3.4, ...</td>\n",
       "      <td>[(3.0, cm), (14.0, cm), (3.4, cm), (4.0, cm)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>142</td>\n",
       "      <td>https://m.media-amazon.com/images/I/310qlaeUSA...</td>\n",
       "      <td>449805</td>\n",
       "      <td>depth</td>\n",
       "      <td>downs/310qlaeUSAL.jpg</td>\n",
       "      <td>310qlaeUSAL.jpg</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>144</td>\n",
       "      <td>https://m.media-amazon.com/images/I/310rX4WoAF...</td>\n",
       "      <td>704724</td>\n",
       "      <td>depth</td>\n",
       "      <td>downs/310rX4WoAFL.jpg</td>\n",
       "      <td>310rX4WoAFL.jpg</td>\n",
       "      <td>[(90.0, centimetre), (3.9, inch)]</td>\n",
       "      <td>[(90.0, cm), (3.9, in)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>147</td>\n",
       "      <td>https://m.media-amazon.com/images/I/310uxz1C1+...</td>\n",
       "      <td>825954</td>\n",
       "      <td>item_volume</td>\n",
       "      <td>downs/310uxz1C1+L.jpg</td>\n",
       "      <td>310uxz1C1+L.jpg</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 8 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T22:56:49.354055Z",
     "start_time": "2024-09-15T22:56:49.345526Z"
    }
   },
   "source": [
    "t = sample_test_out[\"extracted_text\"].to_list()\n",
    "\n",
    "res = []\n",
    "\n",
    "for row  in t:\n",
    "\ttemp = set()\n",
    "\tfor pair in row:\n",
    "\n",
    "\t\tif(pair[1] in allowed_units):\n",
    "\t\t\ttemp.add(f\"{pair[0]} {pair[1]}\")\n",
    "\n",
    "\t\t\n",
    "\tres.append(list(temp))\n",
    "\n",
    "sample_test[\"prediction\"] = res\n",
    "\n",
    "sample_test[\"prediction\"] = sample_test[\"prediction\"].apply(lambda lst : \"\" if(len(lst) == 0) else lst[0])\n",
    "\n",
    "\n",
    "\n",
    "final_out = sample_test.copy(deep=True)\n",
    "\n",
    "final_out = final_out[[\"index\", \"prediction\"]]\n",
    "# final_out = final_out[[\"prediction\"]]\n",
    "\n",
    "final_out.to_csv(\"test_out.csv\", index=False)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reddy\\AppData\\Local\\Temp\\ipykernel_25504\\2765454049.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sample_test[\"prediction\"] = res\n",
      "C:\\Users\\reddy\\AppData\\Local\\Temp\\ipykernel_25504\\2765454049.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sample_test[\"prediction\"] = sample_test[\"prediction\"].apply(lambda lst : \"\" if(len(lst) == 0) else lst[0])\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T22:56:09.341814Z",
     "start_time": "2024-09-15T22:56:09.317795Z"
    }
   },
   "source": [
    "sample_test"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    index                                         image_link  group_id  \\\n",
       "0       0  https://m.media-amazon.com/images/I/110EibNycl...    156839   \n",
       "1       1  https://m.media-amazon.com/images/I/11TU2clswz...    792578   \n",
       "2       4  https://m.media-amazon.com/images/I/11gHj8dhhr...    792578   \n",
       "3       7  https://m.media-amazon.com/images/I/11lshEUmCr...    156839   \n",
       "4       8  https://m.media-amazon.com/images/I/21+i52HRW4...    478357   \n",
       "..    ...                                                ...       ...   \n",
       "95    139  https://m.media-amazon.com/images/I/310oxdFmgL...    913156   \n",
       "96    141  https://m.media-amazon.com/images/I/310p+AOeZ6...    452717   \n",
       "97    142  https://m.media-amazon.com/images/I/310qlaeUSA...    449805   \n",
       "98    144  https://m.media-amazon.com/images/I/310rX4WoAF...    704724   \n",
       "99    147  https://m.media-amazon.com/images/I/310uxz1C1+...    825954   \n",
       "\n",
       "    entity_name             image_path       image_name  \\\n",
       "0        height  downs/110EibNyclL.jpg  110EibNyclL.jpg   \n",
       "1         width  downs/11TU2clswzL.jpg  11TU2clswzL.jpg   \n",
       "2         depth  downs/11gHj8dhhrL.jpg  11gHj8dhhrL.jpg   \n",
       "3        height  downs/11lshEUmCrL.jpg  11lshEUmCrL.jpg   \n",
       "4         width  downs/21+i52HRW4L.jpg  21+i52HRW4L.jpg   \n",
       "..          ...                    ...              ...   \n",
       "95        width  downs/310oxdFmgLL.jpg  310oxdFmgLL.jpg   \n",
       "96       height  downs/310p+AOeZ6L.jpg  310p+AOeZ6L.jpg   \n",
       "97        depth  downs/310qlaeUSAL.jpg  310qlaeUSAL.jpg   \n",
       "98        depth  downs/310rX4WoAFL.jpg  310rX4WoAFL.jpg   \n",
       "99  item_volume  downs/310uxz1C1+L.jpg  310uxz1C1+L.jpg   \n",
       "\n",
       "                                       extracted_text  \\\n",
       "0                                                  []   \n",
       "1           [(42.0, centimetre), (200.0, centimetre)]   \n",
       "2            [(10.5, centimetre), (90.0, centimetre)]   \n",
       "3                                                  []   \n",
       "4                                                       \n",
       "..                                                ...   \n",
       "95          [(100.0, millimetre), (11.5, millimetre)]   \n",
       "96  [(3.0, centimetre), (14.0, centimetre), (3.4, ...   \n",
       "97                                                 []   \n",
       "98                  [(90.0, centimetre), (3.9, inch)]   \n",
       "99                                                 []   \n",
       "\n",
       "                                     cleaned_text        prediction  \n",
       "0                                              []                    \n",
       "1                       [(42.0, cm), (200.0, cm)]  200.0 centimetre  \n",
       "2                        [(10.5, cm), (90.0, cm)]   90.0 centimetre  \n",
       "3                                              []                    \n",
       "4                                                                    \n",
       "..                                            ...               ...  \n",
       "95                      [(100.0, mm), (11.5, mm)]   11.5 millimetre  \n",
       "96  [(3.0, cm), (14.0, cm), (3.4, cm), (4.0, cm)]    3.4 centimetre  \n",
       "97                                             []                    \n",
       "98                        [(90.0, cm), (3.9, in)]   90.0 centimetre  \n",
       "99                                             []                    \n",
       "\n",
       "[100 rows x 9 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>image_link</th>\n",
       "      <th>group_id</th>\n",
       "      <th>entity_name</th>\n",
       "      <th>image_path</th>\n",
       "      <th>image_name</th>\n",
       "      <th>extracted_text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://m.media-amazon.com/images/I/110EibNycl...</td>\n",
       "      <td>156839</td>\n",
       "      <td>height</td>\n",
       "      <td>downs/110EibNyclL.jpg</td>\n",
       "      <td>110EibNyclL.jpg</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://m.media-amazon.com/images/I/11TU2clswz...</td>\n",
       "      <td>792578</td>\n",
       "      <td>width</td>\n",
       "      <td>downs/11TU2clswzL.jpg</td>\n",
       "      <td>11TU2clswzL.jpg</td>\n",
       "      <td>[(42.0, centimetre), (200.0, centimetre)]</td>\n",
       "      <td>[(42.0, cm), (200.0, cm)]</td>\n",
       "      <td>200.0 centimetre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>https://m.media-amazon.com/images/I/11gHj8dhhr...</td>\n",
       "      <td>792578</td>\n",
       "      <td>depth</td>\n",
       "      <td>downs/11gHj8dhhrL.jpg</td>\n",
       "      <td>11gHj8dhhrL.jpg</td>\n",
       "      <td>[(10.5, centimetre), (90.0, centimetre)]</td>\n",
       "      <td>[(10.5, cm), (90.0, cm)]</td>\n",
       "      <td>90.0 centimetre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>https://m.media-amazon.com/images/I/11lshEUmCr...</td>\n",
       "      <td>156839</td>\n",
       "      <td>height</td>\n",
       "      <td>downs/11lshEUmCrL.jpg</td>\n",
       "      <td>11lshEUmCrL.jpg</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>https://m.media-amazon.com/images/I/21+i52HRW4...</td>\n",
       "      <td>478357</td>\n",
       "      <td>width</td>\n",
       "      <td>downs/21+i52HRW4L.jpg</td>\n",
       "      <td>21+i52HRW4L.jpg</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>139</td>\n",
       "      <td>https://m.media-amazon.com/images/I/310oxdFmgL...</td>\n",
       "      <td>913156</td>\n",
       "      <td>width</td>\n",
       "      <td>downs/310oxdFmgLL.jpg</td>\n",
       "      <td>310oxdFmgLL.jpg</td>\n",
       "      <td>[(100.0, millimetre), (11.5, millimetre)]</td>\n",
       "      <td>[(100.0, mm), (11.5, mm)]</td>\n",
       "      <td>11.5 millimetre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>141</td>\n",
       "      <td>https://m.media-amazon.com/images/I/310p+AOeZ6...</td>\n",
       "      <td>452717</td>\n",
       "      <td>height</td>\n",
       "      <td>downs/310p+AOeZ6L.jpg</td>\n",
       "      <td>310p+AOeZ6L.jpg</td>\n",
       "      <td>[(3.0, centimetre), (14.0, centimetre), (3.4, ...</td>\n",
       "      <td>[(3.0, cm), (14.0, cm), (3.4, cm), (4.0, cm)]</td>\n",
       "      <td>3.4 centimetre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>142</td>\n",
       "      <td>https://m.media-amazon.com/images/I/310qlaeUSA...</td>\n",
       "      <td>449805</td>\n",
       "      <td>depth</td>\n",
       "      <td>downs/310qlaeUSAL.jpg</td>\n",
       "      <td>310qlaeUSAL.jpg</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>144</td>\n",
       "      <td>https://m.media-amazon.com/images/I/310rX4WoAF...</td>\n",
       "      <td>704724</td>\n",
       "      <td>depth</td>\n",
       "      <td>downs/310rX4WoAFL.jpg</td>\n",
       "      <td>310rX4WoAFL.jpg</td>\n",
       "      <td>[(90.0, centimetre), (3.9, inch)]</td>\n",
       "      <td>[(90.0, cm), (3.9, in)]</td>\n",
       "      <td>90.0 centimetre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>147</td>\n",
       "      <td>https://m.media-amazon.com/images/I/310uxz1C1+...</td>\n",
       "      <td>825954</td>\n",
       "      <td>item_volume</td>\n",
       "      <td>downs/310uxz1C1+L.jpg</td>\n",
       "      <td>310uxz1C1+L.jpg</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 9 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 8/88 [00:00<00:02, 31.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full match => ['500.0 gram'] => ['500.0 gram']\n",
      "Partial match => ['0.709 gram', '200.0 milligram', '100.0 milligram', '50.0 milligram', '25.0 milligram', '25.0 milligram', '25.0 milligram', '57.0 gram', '25.0 milligram', '10.0 milligram', '0.51 gram', '0.2 gram', '0.09 gram', '25.0 milligram', '5.0 milligram'] => ['0.709 gram']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 16/88 [00:00<00:02, 28.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partial match => ['30.0 kilogram', '30.0 kilogram'] => ['30.0 kilogram']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 27/88 [00:00<00:02, 29.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partial match => ['0.28 inch', '7.0 millimetre', '0.07 inch', '1.8 millimetre', '2.0 inch', '2.7 gram', '405.0 millimetre'] => ['2.7 gram']\n",
      "Partial match => ['9.1 centimetre', '36.8 centimetre', '481.0 volt', '48.0 volt', '48.0 volt', '44.0 kilogram'] => ['4.1 kilogram', '48.0 volt']\n",
      "Partial match => ['9.1 centimetre', '36.8 centimetre', '481.0 volt', '48.0 volt', '48.0 volt', '44.0 kilogram'] => ['4.1 kilogram', '48.0 volt']\n",
      "Partial match => ['26.0 centimetre', '40.0 centimetre', '158.0 gram'] => ['158.0 gram']\n",
      "Full match => ['158.0 gram'] => ['158.0 gram']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 36/88 [00:01<00:01, 27.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partial match => ['50.0 millilitre', '18.55 gram', '50.0 millilitre'] => ['18.55 gram']\n",
      "Partial match => ['50.0 millilitre', '6.0 hour', '50.0 millilitre', '18.55 gram'] => ['18.55 gram']\n",
      "Partial match => ['50.0 millilitre', '18.55 gram'] => ['18.55 gram']\n",
      "Partial match => ['4.0 centimetre', '26.0 gram'] => ['26.0 gram']\n",
      "Partial match => ['36.0 volt', '135.0 millimetre'] => ['800.0 watt', '36.0 volt']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 43/88 [00:01<00:01, 28.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partial match => ['36.0 volt', '135.0 millimetre'] => ['800.0 watt', '36.0 volt']\n",
      "Full match => ['330.0 pound'] => ['330.0 pound']\n",
      "Full match => ['150.0 watt'] => ['150.0 watt']\n",
      "Partial match => ['150.0 watt', '305.0 millimetre', '32.0 millimetre'] => ['150.0 watt']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 50/88 [00:01<00:01, 30.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full match => ['30.0 watt'] => ['30.0 watt']\n",
      "Partial match => ['65.0 watt', '30.0 watt'] => ['30.0 watt']\n",
      "Partial match => ['15.5 gram', '0.0 centimetre', '3.5 centimetre'] => ['15.5 gram']\n",
      "****************************************************************************************************\n",
      "Full accuracy = 5.681818181818182 %\n",
      "Partial accuracy = 17.045454545454543 %\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# import tqdm\n",
    "# \n",
    "# def sample_accuracy():\n",
    "# \n",
    "# \n",
    "# \tfull_match = 0\n",
    "# \tpartial_match = 0\n",
    "# \n",
    "# \tfor idx, row in tqdm.tqdm(sample_test_out.iterrows(), total=out_df.shape[0]):\n",
    "# \n",
    "# \t\trow = row.to_dict()\n",
    "# \n",
    "# \t\t# print(row)\n",
    "# \n",
    "# \t\timage_path = row[\"image_path\"]\n",
    "# \t\timage_name = row[\"image_name\"]\n",
    "# \t\tpossible = row[\"extracted_text\"]\n",
    "# \n",
    "# \t\tpossible = [f\"{pair[0]} {pair[1].lower()}\" for pair in possible]\n",
    "# \n",
    "# \t\tground_truth = get_ground_truth(image_path, train_df)[\"entity_value\"].tolist()\n",
    "# \n",
    "# \t\t# print(possible, \"=>\", ground_truth)\n",
    "# \n",
    "# \n",
    "# \t\t# print(f\"{image_name} => {cleaned_text_list} => {ground_truth}\")\n",
    "# \n",
    "# \t\tintersection = set(possible).intersection(set(ground_truth))\n",
    "# \n",
    "# \t\t# print(intersection)\n",
    "# \n",
    "# \t\tif(len(possible) == 1 and len(intersection) == 1):\n",
    "# \t\t\tprint(f\"Full match => {possible} => {ground_truth}\")\n",
    "# \t\t\tfull_match += 1\n",
    "# \n",
    "# \t\telif(len(intersection) == 1):\n",
    "# \t\t\tprint(f\"Partial match => {possible} => {ground_truth}\")\n",
    "# \t\t\tpartial_match += 1\n",
    "# \n",
    "# \t\t\n",
    "# \n",
    "# \tprint(\"*\" * 100)\n",
    "# \tprint(f\"Full accuracy = {full_match / out_df.shape[0] * 100} %\")\n",
    "# \tprint(f\"Partial accuracy = {partial_match / out_df.shape[0] * 100} %\")\n",
    "# \tprint(\"*\" * 100)\n",
    "# \n",
    "# \n",
    "# sample_accuracy()\n",
    "# \n",
    "# # train_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
